<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Experts: Mixture of Experts for Implicit Neural Representations</title>
    <meta name="author"
          content="Yizhak Ben-Shabat (Itzik), Chamin Hewa Koneputugodage, Sameera Ramasinghe, and Stephen Gould">
    <meta name="description"
          content="Neural Experts NeurIPS paper project page">
    <meta name="keywords" content="Neural Experts,  INR, Surface Reconstruction, Point Clouds, Mixture of Experts, MoE">

    <link rel="stylesheet" href="./css/index.css">
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.js"></script> <!-- CDN link -->
</head>
<body>

<section class="hero">
    <div class="default-container">
        <div class="title-block">
            <h1 class="title">Neural Experts: Mixture of Experts for Implicit Neural Representations</h1>
            <h2 class="venue">NeurIPS 2024</h2>
        </div>
        <div class="author-section">
            <span class="author">
                <a href="https://www.itzikbs.com/">
                    <img class="image" src="./images/itzik.jpg" alt="Yizhak Ben-Shabat (Itzik)">
                </a> <br/>
                <a href="https://www.itzikbs.com/">Yizhak Ben-Shabat <br> (Itzik)*</a><sup>1</sup>
            </span>
            <span class="author">
                <a href="https://www.linkedin.com/in/chamin-hewa-koneputugodage-b3ba17148/">
                    <img class="image" src="./images/chamin.jpg" alt="Chamin Hewa Koneputugodage">
                </a> <br/>
                <a href="https://www.linkedin.com/in/chamin-hewa-koneputugodage-b3ba17148/">Chamin Hewa
                    <br> Koneputugodage*</a><sup>1</sup>
            </span>
            <span class="author">
                <a href="https://www.linkedin.com/in/sameeraramasinghe/)">
                    <img class="image" src="./images/sameera.png" alt="Sameera Ramasinghe">
                </a> <br/>
                <a href="https://www.linkedin.com/in/sameeraramasinghe/">Sameera Ramasinghe </a><sup>2</sup><br><a>&nbsp</a>
            </span>
            <span class="author">
                <a href="https://cecs.anu.edu.au/people/stephen-gould/">
                    <img class="image" src="./images/steve.jpg" alt="Stephen Gould">
                </a> <br/>
                <a href="https://cecs.anu.edu.au/people/stephen-gould/">Stephen Gould </a><sup>1</sup><br><a>&nbsp</a>
            </span>
        </div>

        <div class="affiliation">
            <sup>1</sup><a>The Australian National University</a>
            &emsp;
            <sup>2</sup><a>Amazon, Australia</a><br>
            <a>*Equal Contribution</a>
        </div>

        <div class="links">
            <span class="link-block">
                <a href="https://arxiv.org/abs/2410.21643" class="button-80">
                    <img class="link-icon" src="./images/pdf.svg" alt="Paper"">
                    <span> Paper</span>
                </a>
            </span>
            <span class="link-block">
                <a href="https://arxiv.org/abs/2410.21643" class="button-80">
                    <img class="link-icon" src="./images/arxiv.png" alt="arxiv">
                    <span> Arxiv</span>
                </a>
            </span>
            <!-- <span class="link-block">
                <a href="coming_soon.html" class="button-80">
                    <img class="link-icon" src="./images/jupyter.svg" alt="Jupter Notebook">
                    <span> Jupter Notebook</span>
                </a>
            </span> -->
            <span class="link-block">
                <a href="https://github.com/sitzikbs/Neural-Experts" class="button-80">
                    <img class="link-icon" src="./images/github.svg" alt="Code">
                    <span> Code</span>
                </a>
            </span>
            <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=bQWpRyM9wYM&list=PLD-7XrNHCcFLDQ6KH7w2xFLe0JWvalYfr&index=3&ab_channel=anucvml" class="button-80">
                    <img class="link-icon" src="./images/youtube.svg" alt="Video">
                    <span> Video</span>
                </a>
            </span> -->
            <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=w2xC2JluMlk&ab_channel=TalkingPapersPodcast" class="button-80">
                    <img class="link-icon" src="./images/youtube.svg" alt="Video">
                    <span> Podcast</span>
                </a>
            </span> -->
        </div>

    </div>
</section>

<section class="teaser-results">
    <div class="default-container">
        <img class="divergence-expl-img" src="./images/neural_experts.png" alt="teaser">
        <p style="text-align: justify">
          <strong>Illustration of the Neural Experts architecture.</strong> It consists of a joint expert encoding, experts, and manager networks.
            Two additional key elements of our approach include the conditioning
          and pretraining of the manager that improve signal reconstruction with fewer parameters.
        </p>

    </div>
</section>


<section class="abstract-section">
    <div class="default-container">
        <div class="abstract">
            <h2 class="abstract-title">Abstract</h2>
            <p class="abstract-text">
              Implicit neural representations (INRs) have proven effective in various tasks including image, shape, audio, and video reconstruction.
              These INRs typically learn the implicit field from sampled input points. This is often done using a single network for the entire domain,
              imposing many global constraints on a single function. In this paper, we propose a mixture of experts (MoE) implicit neural representation
              approach that enables learning local piece-wise continuous functions that simultaneously learns to subdivide the domain and fit locally.
              We show that incorporating a mixture of experts architecture into existing INR formulations provides a boost in speed, accuracy, and memory requirements.
              Additionally, we introduce novel conditioning and pretraining methods for the gating network that improves convergence to the desired solution.
              We evaluate the effectiveness of our approach on multiple reconstruction tasks, including surface reconstruction, image reconstruction,
              and audio signal reconstruction and show improved performance compared to non-MoE methods.
            </p>
        </div>
    </div>
</section>

<!--<section class="main-video-section">-->
<!--    <div class="default-container">-->
<!--        <div class="main-video">-->
<!--            <h2 class="main-video-title">Video</h2>-->
<!--            &lt;!&ndash; <div class="main-video-div">-->
<!--                <iframe src="https://www.youtube.com/embed/bQWpRyM9wYM?rel=0&amp;showinfo=0"-->
<!--                        frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--            </div> &ndash;&gt;-->
<!--            <p style="text-align: justify"><b>Coming Soon!</b></p>-->
<!--        </div>-->
<!--    </div>-->
<!--</section>-->



<section class="explanation-section">
    <div class="default-container" style="display: flex; justify-content: space-around; flex-wrap: wrap;">
        <div class="explanation">
            <h2 class="explanation-title">3D Reconstruction Results </h2>
            <p>
                Our method noticeably captures details (e.g. in the toes, nostrils, and eye of the thai statue).
                The expert selection (provided by the manager) provides some level of segmentation by subdividing space.
                The error colormap shows that our reconstruction produces small errors (lighter indicates higher distance to the ground truth surface).
            </p>
        </div>
        <!-- Model Viewer 1 -->
        <div class="model-viewer-container">
            <h5>Armadillo</h5>
            <div class="model-viewer-box">
                <model-viewer
                    id="modelViewer1"
                    alt="Armadillo"
                    src="meshes/armadillo/mesh.glb"
                    exposure=".5"
                    camera-orbit="0deg 75deg 105%"
                    auto-rotate
                    camera-controls
                    orientation="0deg 0deg 180deg 0deg">
                </model-viewer>
            </div>
            <div class="buttons">
                <button onclick="switchModel('modelViewer1', 'meshes/armadillo/mesh.glb')">Mesh</button>
                <button onclick="switchModel('modelViewer1', 'meshes/armadillo/errors.glb')">Error</button>
                <button onclick="switchModel('modelViewer1', 'meshes/armadillo/experts.glb')">Experts</button>
            </div>
        </div>

        <!-- Model Viewer 2 -->
        <div class="model-viewer-container">
            <h5>Thai Statue</h5>
            <div class="model-viewer-box">
                <model-viewer
                    id="modelViewer2"
                    alt="Thai Statue"
                    src="meshes/thai_statue/mesh.glb"
                    exposure=".5"
                    camera-orbit="0deg 75deg 105%"
                    auto-rotate
                    camera-controls>
                </model-viewer>
            </div>
            <div class="buttons">
                <button onclick="switchModel('modelViewer2', 'meshes/thai_statue/mesh.glb')">Mesh</button>
                <button onclick="switchModel('modelViewer2', 'meshes/thai_statue/errors.glb')">Error</button>
                <button onclick="switchModel('modelViewer2', 'meshes/thai_statue/experts.glb')">Experts</button>
            </div>
        </div>

        <!-- Model Viewer 3 -->
        <div class="model-viewer-container">
            <h5>Dragon</h5>
            <div class="model-viewer-box">
                <model-viewer
                    id="modelViewer3"
                    alt="Dragon"
                    src="meshes/dragon/mesh.glb"
                    exposure=".5"
                    camera-orbit="0deg 75deg 105%"
                    auto-rotate
                    camera-controls
                    orientation="0deg 0deg 180deg 0deg">
                </model-viewer>
            </div>
            <div class="buttons">
                <button onclick="switchModel('modelViewer3', 'meshes/dragon/mesh.glb')">Mesh</button>
                <button onclick="switchModel('modelViewer3', 'meshes/dragon/errors.glb')">Error</button>
                <button onclick="switchModel('modelViewer3', 'meshes/dragon/experts.glb')">Experts</button>
            </div>
        </div>

        <!-- Model Viewer 4 -->
        <div class="model-viewer-container">
            <h5>Lucy</h5>
            <div class="model-viewer-box">
                <model-viewer
                    id="modelViewer4"
                    alt="Lucy"
                    src="meshes/lucy/mesh.glb"
                    exposure=".5"
                    camera-orbit="0deg 75deg 105%"
                    auto-rotate
                    camera-controls
                    orientation="0deg -90deg 180deg 0deg">
                </model-viewer>
            </div>
            <div class="buttons">
                <button onclick="switchModel('modelViewer4', 'meshes/lucy/mesh.glb')">Mesh</button>
                <button onclick="switchModel('modelViewer4', 'meshes/lucy/errors.glb')">Error</button>
                <button onclick="switchModel('modelViewer4', 'meshes/lucy/experts.glb')">Experts</button>
            </div>
        </div>

    </div>
    <div class="default-container">
        <div class="explanation">
            <h2 class="explanation-title">Image Reconstruction Results </h2>
            <img class="image" src="./images/img_reconstruction_inr.png" alt="image reconstruction results">
            <p>
                 Qualitative (left) and quantitative (right) results.
                Showing image reconstruction (top), gradients (middle), and laplacian (bottom) for
                (a) GT, (b) SoftPlus, (c) SoftPlus Wider, (d) Our SoftPlus MoE,  (e) SIREN, (f) SIREN Wider, (g) Naive MoE, and (h) Our SIREN Neural Experts.
                The quantitative results (right) report PSNR as training progresses and show that our Neural Experts architecture with Sine activations outperforms all baselines.
            </p>
        </div>
    </div>

    <div class="default-container">
        <div class="explanation">
            <h2 class="explanation-title">Audio Reconstruction Results </h2>
            <img class="image" src="./images/audio_recon.png" alt="audio reconstruction results">
            <p>
                Two speakers audio reconstruction is presented. Within each waveform block, the rows represent the ground truth, reconstruction, and error visu-
                alization from top to bottom. For our Neural Experts we color code the different experts on the reconstructed waveform.
            </p>
        </div>
    </div>
</section>

<script>
    function switchModel(viewerId, modelSrc) {
        const modelViewer = document.getElementById(viewerId);
        modelViewer.src = modelSrc; // Change the src attribute to the new model file
    }
</script>
<!-- <section class="thanks-section">
    <div class="default-container">
        <div class="thanks">
            <h2 class="thanks-title">Acknowledgements</h2>
            <p class="thanks-text">
                This project has received funding from the European Union's Horizon 2020 research and innovation
                programme under the Marie Sklodowska-Curie grant agreement No 893465
            </p>
        </div>
    </div>
</section> -->

<section class="explanation-section">
    <div class="default-container">
        <div class="explanation">
            <h2 class="explanation-title">Mixture of Experts for INRs - Manager Insights</h2>
            <br>
            <p>
              The manager network provides control over the learned representation. It essentially assigns different parts of the coordinate space to different sub-networks (experts).
               A manager's assignment change can accomodiate sharp discontinuity in the data.
               It can also be pretrained using some prior (e.g. segmentation). Our experiments show that a random manager initialization performs best as the underlaying segmentation appears naturally from the training process.

              <img class="image" src="./images/manager_pretraining.png" alt="manager_pretraining">

              Manager pretraining. Visualizing the experts selected by the manager after the pretraining
              stage (top row) and after the full network training (bottom row) for different pretraining ablations.
            </p>
            <br>
        </div>
    </div>

</section>

<section class="reference-section">
    <div class="default-container">
        <div class="ref">
            <h2 class="ref-title">BibTeX</h2>
            <div class="bibtex">
<pre><code>@inproceedings{ben2024neuralexperts,
    title={Neural Experts: Mixture of Experts for Implicit Neural Representations},
    author={Ben-Shabat, Yizhak and Hewa Koneputugodage, Chamin and Ramasinghe, Sameera and Gould, Stephen},
    booktitle={Advances in Neural Information Processing Systems (NeurIPS},
    year={2024}
  }</code></pre>
            </div>
        </div>
    </div>
</section>



</body>
</html>
